algo: "DQN"
env: "ALE/RiverRaid-v5"
total_timesteps: 5000000  # Increased for complex fuel management
learning_rate: 0.00025
buffer_size: 1000000
learning_starts: 50000
batch_size: 32
exploration_fraction: 0.1
exploration_final_eps: 0.01
train_freq: 4
gradient_steps: 1

# Network optimization
gamma: 0.99
target_update_interval: 1000
frame_stack: 4
double_q: true
prioritized_replay: true
prioritized_replay_alpha: 0.6
prioritized_replay_beta0: 0.4
dueling: true
noisy_nets: true  # Parameter space noise for better exploration

# Preprocessing
scale_rewards: true
normalize_frames: true
terminal_on_life_loss: true
max_grad_norm: 10

# Evaluation settings
eval_episodes: 100
eval_freq: 25000
eval_deterministic: true
render_eval: false
success_threshold: 1000.0  # River Raid specific

# Checkpointing
save_freq: 100000
checkpoint_path: "models/river_raid/checkpoints"
keep_checkpoints: 5

# Model metadata
model_class: "DQN"
model_version: "1.0.0"
description: "River Raid DQN agent with Dueling + Noisy Nets for complex navigation"

# Hardware settings
n_envs: 4
n_steps: 4
device: "auto"

# Game specific settings
reward_shaping:
  fuel_bonus: 2.0        # Higher reward for fuel management
  score_multiplier: 1.0
  death_penalty: -1.0
  progress_bonus: 0.1    # Small bonus for forward progress

# Custom reward wrapper settings
use_custom_rewards: true
reward_normalization: true
clip_rewards: true

# Visualization
viz_interval: 25000
video_interval: 100000
video_length: 400
checkpoint_interval: 100000
demo_mode: false

# Model architecture
policy: "CnnPolicy"
features_extractor: "NatureCNN"
features_dim: 512 